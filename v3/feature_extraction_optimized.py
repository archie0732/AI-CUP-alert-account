import polars as pl
import pandas as pd
import numpy as np
from datetime import datetime
from tqdm import tqdm
import warnings
from path import DATA_PATH, OUTPUT_PATH

warnings.filterwarnings("ignore")

print("=" * 120)
print("ğŸš€ å®Œæ•´å„ªåŒ–ç‰¹å¾µæå–æµç¨‹ï¼ˆå‘é‡åŒ– + é€²åº¦æ¢ï¼‰")
print("=" * 120)

start = datetime.now()

# ==================== [1] Polars æ¥µé€Ÿè¼‰å…¥ ====================
print("[1/6] Polars æ¥µé€Ÿè¼‰å…¥æ•¸æ“š...\n")


# è¼‰å…¥äº¤æ˜“æ•¸æ“š
df_txn = pl.scan_csv(f"{DATA_PATH}/acct_transaction.csv").with_columns(
    [
        pl.col("txn_date").cast(pl.Int32),
        pl.col("txn_amt").cast(pl.Float64, strict=False).fill_null(0.0),
    ]
)

# è¼‰å…¥æ¨™ç±¤
df_alert = pl.read_csv(f"{DATA_PATH}/acct_alert.csv")
df_predict = pl.read_csv(f"{DATA_PATH}/acct_predict.csv")

alert_accounts = set(df_alert["acct"].to_list())
test_accounts = set(df_predict["acct"].to_list())

df_txn_collected = df_txn.collect()

print(f"  äº¤æ˜“æ•¸: {len(df_txn_collected):,}")
print(f"  è­¦ç¤ºå¸³æˆ¶: {len(alert_accounts):,}")
print(f"  æ¸¬è©¦å¸³æˆ¶: {len(test_accounts):,}\n")

# ==================== [2] Polars æ‰¹é‡ç‰¹å¾µè¨ˆç®— ====================
print("[2/6] Polars æ‰¹é‡è¨ˆç®—æ ¸å¿ƒç‰¹å¾µï¼ˆæ¥µé€Ÿï¼‰...\n")

# æ ¸å¿ƒçµ±è¨ˆç‰¹å¾µï¼ˆPolars å‘é‡åŒ–ï¼‰
features_from = df_txn_collected.group_by("from_acct").agg(
    [
        pl.count().alias("out_txn_count"),
        pl.col("txn_amt").sum().alias("total_outflow"),
        pl.col("txn_amt").mean().alias("avg_out_amt"),
        pl.col("txn_amt").std().alias("std_out_amt"),
        pl.col("txn_amt").min().alias("min_out_amt"),
        pl.col("txn_amt").max().alias("max_out_amt"),
        pl.col("txn_date").min().alias("first_out_date"),
        pl.col("txn_date").max().alias("last_out_date"),
        pl.col("txn_date").n_unique().alias("active_out_days"),
        pl.col("to_acct").n_unique().alias("unique_recipients"),
    ]
)

features_to = df_txn_collected.group_by("to_acct").agg(
    [
        pl.count().alias("in_txn_count"),
        pl.col("txn_amt").sum().alias("total_inflow"),
        pl.col("txn_amt").mean().alias("avg_in_amt"),
        pl.col("txn_date").min().alias("first_in_date"),
        pl.col("txn_date").max().alias("last_in_date"),
        pl.col("from_acct").n_unique().alias("unique_senders"),
    ]
)

print(f"  âœ… Polars æ ¸å¿ƒç‰¹å¾µå®Œæˆ: {(datetime.now() - start).total_seconds():.1f} ç§’\n")

# ==================== [3] åˆä½µå’Œè¡ç”Ÿç‰¹å¾µ ====================
print("[3/6] åˆä½µç‰¹å¾µä¸¦è¨ˆç®—è¡ç”Ÿç‰¹å¾µ...\n")

# è½‰ç‚º Pandas
df_features_from = features_from.to_pandas().rename(columns={"from_acct": "account"})
df_features_to = features_to.to_pandas().rename(columns={"to_acct": "account"})

# åˆä½µ
df_features = df_features_from.merge(df_features_to, on="account", how="outer").fillna(
    0
)

# è¡ç”Ÿç‰¹å¾µ
df_features["total_transactions"] = (
    df_features["out_txn_count"] + df_features["in_txn_count"]
)
df_features["net_flow"] = df_features["total_inflow"] - df_features["total_outflow"]
df_features["turnover_ratio"] = df_features["total_outflow"] / (
    df_features["total_inflow"] + 1
)

# æ™‚é–“è·¨åº¦
df_features["first_date"] = df_features[["first_out_date", "first_in_date"]].min(axis=1)
df_features["last_date"] = df_features[["last_out_date", "last_in_date"]].max(axis=1)
df_features["days_span"] = df_features["last_date"] - df_features["first_date"] + 1

# æ´»èºåº¦
df_features["total_active_days"] = df_features[
    ["active_out_days", "in_txn_count"]
].apply(lambda x: max(x["active_out_days"], 1), axis=1)
df_features["txn_frequency"] = df_features["total_transactions"] / (
    df_features["days_span"] + 1
)

# å°æ‰‹æ–¹å¤šæ¨£æ€§
df_features["total_counterparties"] = (
    df_features["unique_recipients"] + df_features["unique_senders"]
)
df_features["counterparty_concentration"] = df_features["total_transactions"] / (
    df_features["total_counterparties"] + 1
)

print(f"  âœ… åŸºç¤ç‰¹å¾µå®Œæˆ\n")

# ==================== [4] è¤‡é›œç‰¹å¾µï¼ˆå‘é‡åŒ– + é€²åº¦æ¢ï¼‰====================
print("[4/6] è¨ˆç®—è¤‡é›œç‰¹å¾µï¼ˆå‘é‡åŒ– + é€²åº¦æ¢ï¼‰...\n")

# è½‰ç‚º Pandas
df_txn_pd = df_txn_collected.to_pandas()

# ========== [1/8] è™•ç†æ™‚é–“ç‰¹å¾µ ==========
print("  [1/8] è™•ç†æ™‚é–“ç‰¹å¾µ...")
df_txn_pd["txn_hour"] = pd.to_datetime(
    df_txn_pd["txn_time"], format="%H:%M:%S", errors="coerce"
).dt.hour

# ========== [2/8] å¤œé–“äº¤æ˜“æ¯”ä¾‹ï¼ˆå‘é‡åŒ–ï¼‰==========
print("  [2/8] è¨ˆç®—å¤œé–“äº¤æ˜“æ¯”ä¾‹...")
df_txn_pd["is_night"] = (
    (df_txn_pd["txn_hour"] >= 22) | (df_txn_pd["txn_hour"] < 6)
).astype(int)

night_from = df_txn_pd.groupby("from_acct")["is_night"].agg(["sum", "count"])
night_from["night_ratio_from"] = night_from["sum"] / night_from["count"]

night_to = df_txn_pd.groupby("to_acct")["is_night"].agg(["sum", "count"])
night_to["night_ratio_to"] = night_to["sum"] / night_to["count"]

# ========== [3/8] è·¨è¡Œäº¤æ˜“æ¯”ä¾‹ï¼ˆå‘é‡åŒ–ï¼‰==========
print("  [3/8] è¨ˆç®—è·¨è¡Œäº¤æ˜“æ¯”ä¾‹...")
df_txn_pd["is_other_bank_from"] = (df_txn_pd["to_acct_type"] == "02").astype(int)
df_txn_pd["is_other_bank_to"] = (df_txn_pd["from_acct_type"] == "02").astype(int)

other_bank_from = df_txn_pd.groupby("from_acct")["is_other_bank_from"].agg(
    ["sum", "count"]
)
other_bank_from["other_bank_ratio_from"] = (
    other_bank_from["sum"] / other_bank_from["count"]
)

other_bank_to = df_txn_pd.groupby("to_acct")["is_other_bank_to"].agg(["sum", "count"])
other_bank_to["other_bank_ratio_to"] = other_bank_to["sum"] / other_bank_to["count"]

# ========== [4/8] UNK é€šè·¯æ¯”ä¾‹ï¼ˆå‘é‡åŒ–ï¼‰==========
print("  [4/8] è¨ˆç®— UNK é€šè·¯æ¯”ä¾‹...")
df_txn_pd["is_unk"] = (df_txn_pd["channel_type"] == "UNK").astype(int)

unk_from = df_txn_pd.groupby("from_acct")["is_unk"].agg(["sum", "count"])
unk_from["unk_ratio_from"] = unk_from["sum"] / unk_from["count"]

unk_to = df_txn_pd.groupby("to_acct")["is_unk"].agg(["sum", "count"])
unk_to["unk_ratio_to"] = unk_to["sum"] / unk_to["count"]

# ========== [5/8] æœ€å¾Œ 7 å¤©æ´»èºåº¦ï¼ˆå‘é‡åŒ–ï¼‰==========
print("  [5/8] è¨ˆç®—æœ€å¾Œ 7 å¤©æ´»èºåº¦...")

# æ‰¾æ¯å€‹å¸³æˆ¶çš„æœ€å¾Œæ—¥æœŸ
last_dates_from = df_txn_pd.groupby("from_acct")["txn_date"].max().to_dict()
last_dates_to = df_txn_pd.groupby("to_acct")["txn_date"].max().to_dict()

# æ¨™è¨˜æœ€å¾Œ 7 å¤©çš„äº¤æ˜“
df_txn_pd["is_late_from"] = df_txn_pd.apply(
    lambda x: 1 if x["txn_date"] > last_dates_from.get(x["from_acct"], 0) - 7 else 0,
    axis=1,
)
df_txn_pd["is_late_to"] = df_txn_pd.apply(
    lambda x: 1 if x["txn_date"] > last_dates_to.get(x["to_acct"], 0) - 7 else 0, axis=1
)

late_from = df_txn_pd.groupby("from_acct")["is_late_from"].agg(["sum", "count"])
late_from["late_ratio_from"] = late_from["sum"] / late_from["count"]

late_to = df_txn_pd.groupby("to_acct")["is_late_to"].agg(["sum", "count"])
late_to["late_ratio_to"] = late_to["sum"] / late_to["count"]

# ========== [6/8] å¿«é€Ÿè½‰å¸³æ¯”ä¾‹ï¼ˆç°¡åŒ–å‘é‡åŒ–ï¼‰==========
print("  [6/8] è¨ˆç®—å¿«é€Ÿè½‰å¸³æ¯”ä¾‹...")

quick_from = (
    df_txn_pd.groupby(["from_acct", "txn_date"]).size().reset_index(name="daily_out")
)
quick_to = (
    df_txn_pd.groupby(["to_acct", "txn_date"]).size().reset_index(name="daily_in")
)

quick_merged = quick_from.merge(
    quick_to,
    left_on=["from_acct", "txn_date"],
    right_on=["to_acct", "txn_date"],
    how="inner",
)

quick_count = (
    quick_merged.groupby("from_acct")
    .apply(lambda x: (x[["daily_out", "daily_in"]].min(axis=1)).sum())
    .reset_index(name="quick_count")
)

in_count = df_txn_pd.groupby("to_acct").size().reset_index(name="in_count")
quick_ratio = quick_count.merge(
    in_count, left_on="from_acct", right_on="to_acct", how="left"
).fillna(0)
quick_ratio["quick_transfer_ratio"] = quick_ratio["quick_count"] / (
    quick_ratio["in_count"] + 1
)

# ========== [7/8] æ™‚é–“ç†µï¼ˆæ‰¹é‡è¨ˆç®—ï¼‰==========
print("  [7/8] è¨ˆç®—æ™‚é–“ç†µ...")

# æŒ‰å¸³æˆ¶æ”¶é›†å°æ™‚æ•¸æ“š
from_hours_dict = (
    df_txn_pd.groupby("from_acct")["txn_hour"]
    .apply(lambda x: x.dropna().values.astype(np.float64))
    .to_dict()
)

to_hours_dict = (
    df_txn_pd.groupby("to_acct")["txn_hour"]
    .apply(lambda x: x.dropna().values.astype(np.float64))
    .to_dict()
)

# è¨ˆç®—æ™‚é–“ç†µ
print("    è¨ˆç®— from_acct æ™‚é–“ç†µ...")
time_entropy_from_data = []
for acct, hours in tqdm(from_hours_dict.items(), desc="    from_acct", leave=False):
    if len(hours) > 0:
        # çµ±è¨ˆæ¯å€‹å°æ™‚çš„é »ç‡
        hour_counts = np.zeros(24)
        for h in hours:
            if 0 <= h < 24:
                hour_counts[int(h)] += 1

        # è¨ˆç®—ç†µ
        total = np.sum(hour_counts)
        if total > 0:
            probs = hour_counts / total
            entropy = -np.sum(probs[probs > 0] * np.log2(probs[probs > 0]))
        else:
            entropy = 0.0
    else:
        entropy = 0.0

    time_entropy_from_data.append({"account": acct, "time_entropy_from": entropy})

time_entropy_from = pd.DataFrame(time_entropy_from_data)

print("    è¨ˆç®— to_acct æ™‚é–“ç†µ...")
time_entropy_to_data = []
for acct, hours in tqdm(to_hours_dict.items(), desc="    to_acct", leave=False):
    if len(hours) > 0:
        hour_counts = np.zeros(24)
        for h in hours:
            if 0 <= h < 24:
                hour_counts[int(h)] += 1

        total = np.sum(hour_counts)
        if total > 0:
            probs = hour_counts / total
            entropy = -np.sum(probs[probs > 0] * np.log2(probs[probs > 0]))
        else:
            entropy = 0.0
    else:
        entropy = 0.0

    time_entropy_to_data.append({"account": acct, "time_entropy_to": entropy})

time_entropy_to = pd.DataFrame(time_entropy_to_data)

# ========== [8/8] åˆä½µæ‰€æœ‰è¤‡é›œç‰¹å¾µ ==========
print("  [8/8] åˆä½µæ‰€æœ‰è¤‡é›œç‰¹å¾µ...")

# ç²å–æ‰€æœ‰å¸³æˆ¶
all_accounts = df_features["account"].unique()

# åˆå§‹åŒ–è¤‡é›œç‰¹å¾µ DataFrame
df_complex = pd.DataFrame({"account": all_accounts})

# åˆä½µå¤œé–“äº¤æ˜“
df_complex = df_complex.merge(
    night_from[["night_ratio_from"]]
    .reset_index()
    .rename(columns={"from_acct": "account"}),
    on="account",
    how="left",
)
df_complex = df_complex.merge(
    night_to[["night_ratio_to"]].reset_index().rename(columns={"to_acct": "account"}),
    on="account",
    how="left",
)
df_complex["night_txn_ratio"] = df_complex[["night_ratio_from", "night_ratio_to"]].mean(
    axis=1
)

# åˆä½µè·¨è¡Œäº¤æ˜“
df_complex = df_complex.merge(
    other_bank_from[["other_bank_ratio_from"]]
    .reset_index()
    .rename(columns={"from_acct": "account"}),
    on="account",
    how="left",
)
df_complex = df_complex.merge(
    other_bank_to[["other_bank_ratio_to"]]
    .reset_index()
    .rename(columns={"to_acct": "account"}),
    on="account",
    how="left",
)
df_complex["other_bank_ratio"] = df_complex[
    ["other_bank_ratio_from", "other_bank_ratio_to"]
].mean(axis=1)

# åˆä½µ UNK é€šè·¯
df_complex = df_complex.merge(
    unk_from[["unk_ratio_from"]].reset_index().rename(columns={"from_acct": "account"}),
    on="account",
    how="left",
)
df_complex = df_complex.merge(
    unk_to[["unk_ratio_to"]].reset_index().rename(columns={"to_acct": "account"}),
    on="account",
    how="left",
)
df_complex["unk_channel_ratio"] = df_complex[["unk_ratio_from", "unk_ratio_to"]].mean(
    axis=1
)

# åˆä½µæœ€å¾Œ 7 å¤©
df_complex = df_complex.merge(
    late_from[["late_ratio_from"]]
    .reset_index()
    .rename(columns={"from_acct": "account"}),
    on="account",
    how="left",
)
df_complex = df_complex.merge(
    late_to[["late_ratio_to"]].reset_index().rename(columns={"to_acct": "account"}),
    on="account",
    how="left",
)
df_complex["late_txn_ratio"] = df_complex[["late_ratio_from", "late_ratio_to"]].mean(
    axis=1
)

# åˆä½µå¿«é€Ÿè½‰å¸³
df_complex = df_complex.merge(
    quick_ratio[["from_acct", "quick_transfer_ratio"]].rename(
        columns={"from_acct": "account"}
    ),
    on="account",
    how="left",
)

# åˆä½µæ™‚é–“ç†µ
df_complex = df_complex.merge(time_entropy_from, on="account", how="left")
df_complex = df_complex.merge(time_entropy_to, on="account", how="left")
df_complex["time_entropy"] = df_complex[["time_entropy_from", "time_entropy_to"]].mean(
    axis=1
)

# å¡«å……ç¼ºå¤±å€¼
df_complex = df_complex.fillna(0)

# è¨ˆç®—çµ„åˆç‰¹å¾µ
df_complex = df_complex.merge(
    df_features[["account", "total_active_days", "total_transactions"]],
    on="account",
    how="left",
)

df_complex["cross_bank_intensity"] = df_complex["other_bank_ratio"] * (
    df_complex["total_transactions"] / 100
)
df_complex["late_activity_intensity"] = (
    df_complex["late_txn_ratio"] * df_complex["total_transactions"]
) / (df_complex["total_active_days"] + 1)

# æ—¥å‡æµé‡
inflow_daily = df_txn_pd.groupby("to_acct")["txn_amt"].sum().reset_index()
inflow_daily = inflow_daily.merge(
    df_features[["account", "total_active_days"]],
    left_on="to_acct",
    right_on="account",
    how="left",
)
inflow_daily["avg_daily_inflow"] = inflow_daily["txn_amt"] / (
    inflow_daily["total_active_days"] + 1
)
inflow_daily = inflow_daily[["to_acct", "avg_daily_inflow"]].rename(
    columns={"to_acct": "account"}
)

outflow_daily = df_txn_pd.groupby("from_acct")["txn_amt"].sum().reset_index()
outflow_daily = outflow_daily.merge(
    df_features[["account", "total_active_days"]],
    left_on="from_acct",
    right_on="account",
    how="left",
)
outflow_daily["avg_daily_outflow"] = outflow_daily["txn_amt"] / (
    outflow_daily["total_active_days"] + 1
)
outflow_daily = outflow_daily[["from_acct", "avg_daily_outflow"]].rename(
    columns={"from_acct": "account"}
)

df_complex = df_complex.merge(inflow_daily, on="account", how="left")
df_complex = df_complex.merge(outflow_daily, on="account", how="left")

df_complex = df_complex.fillna(0)

# æœ€çµ‚åˆä½µåˆ°ä¸» DataFrame
df_features = df_features.merge(
    df_complex[
        [
            "account",
            "night_txn_ratio",
            "other_bank_ratio",
            "unk_channel_ratio",
            "late_txn_ratio",
            "quick_transfer_ratio",
            "time_entropy",
            "cross_bank_intensity",
            "late_activity_intensity",
            "avg_daily_inflow",
            "avg_daily_outflow",
        ]
    ],
    on="account",
    how="left",
).fillna(0)

print(f"  âœ… è¤‡é›œç‰¹å¾µå®Œæˆ: {(datetime.now() - start).total_seconds():.1f} ç§’\n")

# ==================== [5] é¸æ“‡æœ€çµ‚ 31 å€‹ç‰¹å¾µ ====================
print("[5/6] é¸æ“‡æœ€çµ‚ 31 å€‹ç‰¹å¾µï¼ˆæ­·å²æœ€ä½³çµ„åˆï¼‰...\n")

# 31 å€‹ç‰¹å¾µï¼ˆåŸºæ–¼æ­·å²æœ€ä½³ï¼‰
final_31_features = [
    # åŸºç¤çµ±è¨ˆï¼ˆ10 å€‹ï¼‰
    "total_transactions",
    "total_inflow",
    "total_outflow",
    "avg_out_amt",
    "avg_in_amt",
    "std_out_amt",
    "min_out_amt",
    "max_out_amt",
    "net_flow",
    "turnover_ratio",
    # æ™‚é–“ç‰¹å¾µï¼ˆ6 å€‹ï¼‰
    "days_span",
    "total_active_days",
    "txn_frequency",
    "first_date",
    "last_date",
    "late_txn_ratio",
    # å°æ‰‹æ–¹ç‰¹å¾µï¼ˆ4 å€‹ï¼‰
    "unique_recipients",
    "unique_senders",
    "total_counterparties",
    "counterparty_concentration",
    # è¡Œç‚ºç‰¹å¾µï¼ˆ7 å€‹ï¼‰
    "night_txn_ratio",
    "time_entropy",
    "other_bank_ratio",
    "unk_channel_ratio",
    "quick_transfer_ratio",
    "cross_bank_intensity",
    "late_activity_intensity",
    # æ—¥å‡ç‰¹å¾µï¼ˆ4 å€‹ï¼‰
    "avg_daily_inflow",
    "avg_daily_outflow",
    "out_txn_count",
    "in_txn_count",
]

df_features_final = df_features[["account"] + final_31_features].copy()

print(f"  æœ€çµ‚ç‰¹å¾µæ•¸: {len(final_31_features)}\n")

# ==================== [6] æ·»åŠ æ¨™ç±¤ä¸¦ä¿å­˜ ====================
print("[6/6] æ·»åŠ æ¨™ç±¤ä¸¦ä¿å­˜...\n")

# æ·»åŠ æ¨™ç±¤
df_features_final["is_alert"] = (
    df_features_final["account"].isin(alert_accounts).astype(int)
)
df_features_final["is_test"] = (
    df_features_final["account"].isin(test_accounts).astype(int)
)

# åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†ï¼ˆä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„å¸ƒçˆ¾ç´¢å¼•ï¼‰
train_mask = df_features_final["is_test"] == 0
test_mask = df_features_final["is_test"] == 1

df_train = df_features_final[train_mask].copy()
df_test = df_features_final[test_mask].copy()

# è¨“ç·´é›†æ¨™ç±¤
df_train["label"] = df_train["is_alert"]

print(f"  è¨“ç·´é›†:")
print(f"    ç¸½æ¨£æœ¬: {len(df_train):,}")
print(
    f"    è­¦ç¤ºå¸³æˆ¶: {df_train['label'].sum():,} ({df_train['label'].sum() / len(df_train) * 100:.4f}%)"
)
print(f"    æ­£å¸¸å¸³æˆ¶: {(df_train['label'] == 0).sum():,}\n")

print(f"  æ¸¬è©¦é›†:")
print(f"    ç¸½æ¨£æœ¬: {len(df_test):,}\n")

# ä¿å­˜
train_file = f"{OUTPUT_PATH}/features_31_train_optimized.csv"
test_file = f"{OUTPUT_PATH}/features_31_test_optimized.csv"

df_train[["account", "label"] + final_31_features].to_csv(train_file, index=False)
df_test[["account"] + final_31_features].to_csv(test_file, index=False)

print(f"  âœ… è¨“ç·´é›†å·²ä¿å­˜: features_31_train_optimized.csv")
print(f"  âœ… æ¸¬è©¦é›†å·²ä¿å­˜: features_31_test_optimized.csv\n")

# ==================== æœ€çµ‚å ±å‘Š ====================
elapsed = (datetime.now() - start).total_seconds() / 60

print("=" * 120)
print("âœ… ç‰¹å¾µæå–å®Œæˆ")
print("=" * 120 + "\n")

print(f"â±ï¸  ç¸½è€—æ™‚: {elapsed:.2f} åˆ†é˜\n")

print(f"ğŸ“Š ç‰¹å¾µçµ±è¨ˆ:")
print(f"  ç‰¹å¾µæ•¸: 31 å€‹ï¼ˆæ­·å²æœ€ä½³ï¼‰")
print(f"  ç¸½å¸³æˆ¶æ•¸: {len(df_features_final):,}")
print(f"  è¨“ç·´é›†: {len(df_train):,}")
print(f"  æ¸¬è©¦é›†: {len(df_test):,}\n")

print(f"âœ… é—œéµæ”¹é€²:")
print(f"  1. æå‰è¨ˆç®—æ‰€æœ‰å¸³æˆ¶ç‰¹å¾µï¼ˆä¸€æ¬¡æ€§ï¼‰")
print(f"  2. Polars å‘é‡åŒ–åŠ é€Ÿ")
print(f"  3. é€²åº¦æ¢å¯¦æ™‚é¡¯ç¤º")
print(f"  4. æ­£ç¢ºåˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†ï¼ˆé¿å…æ³„æ¼ï¼‰")
print(f"  5. 31 å€‹æ­·å²æœ€ä½³ç‰¹å¾µ\n")

print(f"ğŸ¯ ä¸‹ä¸€æ­¥:")
print(f"  1. ç”¨é€™ 31 å€‹ç‰¹å¾µåšæ¼¸é€²å¼ç‰¹å¾µé¸æ“‡")
print(f"  2. FLAML è¶…åƒæ•¸å„ªåŒ–")
print(f"  3. æ­£ç¢ºçš„è¨“ç·´/é©—è­‰åˆ†å‰²")
print(f"  4. é¿å…æ•¸æ“šæ³„æ¼\n")

print("=" * 120 + "\n")
